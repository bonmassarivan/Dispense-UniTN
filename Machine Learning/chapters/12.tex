\chapter{Unsupervised Learning}
whiUnsupervised learning works by observing data distribution ${\bf P}_data$,  while lacking a target variable.\\
There are several applications to this: \\
{\bf DIMENSIONALITY REDUCTION}, find a function f that maps each input $x \in \mathscr{X}$ to a lower dimensional embedding, where dim($\mathscr{Y}$) $ < $ dim($\mathscr{X}$). \\
Why would one want to do this? By compressing the input data we also reduce the feature dimensionality making the input more lightweight thus reducing the time for data elaboration.\\
{\bf CLUSTERING} finds a function $f$ that assigns each input $x \in \mathscr{X}$ to a cluster. Why? \\
It allows to analyze data by grouping it together and can also be used to compress data with similar patterns.\\
{\bf DENSITY ESTIMATION} find a probability distribution $f \in \triangle \mathscr{X}$ that fits the data $x \in \mathscr{X}$. Why? 
Allows for explicit estimate of an unknown probability distribution, generating new data and detecting anomalies.\\
\section{Principal component analysis}
